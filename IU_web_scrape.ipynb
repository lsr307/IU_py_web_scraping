{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8eb85d6-6965-4c22-8683-e8dc681ad83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.02309180e+07 0.00000000e+00 1.65000000e+01 2.62999992e+01]\n",
      " [2.02309200e+07 1.00000000e+00 1.50000000e+01 2.40000000e+01]\n",
      " [2.02309200e+07 2.00000000e+00 1.50000000e+01 2.50000000e+01]\n",
      " [2.02309190e+07 0.00000000e+00 1.58000000e+01 2.11000000e+01]\n",
      " [2.02309210e+07 1.00000000e+00 1.50000000e+01 2.70000000e+01]\n",
      " [2.02309210e+07 2.00000000e+00 1.40000000e+01 2.80000000e+01]]\n",
      "[[b'20230919 23:41:54' b'DWD' b'0']\n",
      " [b'20230919 23:41:54' b'Wetter.com' b'1']\n",
      " [b'20230919 23:41:54' b'Wetter.de' b'2']\n",
      " [b'20230920 12:57:33' b'DWD' b'0']\n",
      " [b'20230920 12:57:33' b'Wetter.com' b'1']\n",
      " [b'20230920 12:57:33' b'Wetter.de' b'2']]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from IU_scrape_func import scrape_dwd\n",
    "from IU_scrape_func import scrape_wetter_com\n",
    "from IU_scrape_func import scrape_wetter_de\n",
    "from IU_scrape_func import scrape_sites_append\n",
    "from IU_scrape_func import scrape_sites_open\n",
    "import datetime\n",
    "\n",
    "file_name_sites = 'IU_scrape_sites.csv'\n",
    "file_name_data = 'IU_scrape_data'\n",
    "ds_name_fl = 'data_float'\n",
    "ds_name_st = 'data_string'\n",
    "\n",
    "#Create csv file with websites to scrape\n",
    "#websites = ['https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html',\n",
    "#            'https://www.wetter.com/wetter_aktuell/wettervorhersage/morgen/deutschland/berlin/berlin-tempelhof/DE2823538.html',\n",
    "#            'https://www.wetter.de/wetter/r/162894/diese-woche'\n",
    "#           ]\n",
    "#for x in websites:\n",
    "#    scrape_sites_append(file_name_sites, x)\n",
    "\n",
    "#Open csv file with websites to scrape\n",
    "sites = scrape_sites_open('IU_scrape_sites.csv')\n",
    "\n",
    "#Create & open file if it does not exist\n",
    "try:\n",
    "    file = h5py.File(file_name_data,'r+')\n",
    "except FileNotFoundError:\n",
    "    file = h5py.File(file_name_data,'w')    \n",
    "\n",
    "#Created datasets if they do not exist\n",
    "if not ds_name_fl in list(file.keys()):\n",
    "    dset_fl = file.create_dataset(ds_name_fl, (0,4), maxshape=(None,4), dtype = 'float64') \n",
    "else:\n",
    "    dset_fl = file[f'/{ds_name_fl}']\n",
    "    \n",
    "if not ds_name_st in list(file.keys()):\n",
    "    dt = h5py.string_dtype(encoding='utf-8')\n",
    "    dset_st = file.create_dataset(ds_name_st, (0,3), maxshape=(None,3), dtype = dt) \n",
    "else:\n",
    "    dset_st = file[f'/{ds_name_st}']\n",
    "\n",
    "if not dset_fl.shape[0] == dset_st.shape[0]:\n",
    "    print('Dataset-lengths do not correspond!')\n",
    "\n",
    "data_fl = np.array([scrape_dwd(sites[0]),scrape_wetter_com(sites[1]),scrape_wetter_de(sites[2])])\n",
    "data_st = np.array([[datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\"),'DWD','0'], \\\n",
    "                    [datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\"),'Wetter.com','1'], \\\n",
    "                    [datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\"),'Wetter.de','2']\n",
    "                   ]\n",
    "                  )\n",
    "\n",
    "dset_st.resize(dset_st.shape[0]+3, axis=0)\n",
    "dset_fl.resize(dset_fl.shape[0]+3, axis=0)\n",
    "dset_st[dset_st.shape[0]-3:dset_st.shape[0],:] = data_st\n",
    "dset_fl[dset_fl.shape[0]-3:dset_fl.shape[0],:] = data_fl\n",
    "\n",
    "#To get rid of b: .decode(\"utf-8\")\n",
    "#for x in range(0,len(dset_st)):\n",
    "#    print(dset_st[x,:], dset_fl[x,:])\n",
    "\n",
    "print(dset_fl[...])\n",
    "print(dset_st[...])\n",
    "\n",
    "#Close file\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d405e58-7a5c-4dcd-b9c4-231c15959399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.02309180e+07 0.00000000e+00 1.65000000e+01 2.62999992e+01]\n",
      " [2.02309200e+07 1.00000000e+00 1.50000000e+01 2.40000000e+01]\n",
      " [2.02309200e+07 2.00000000e+00 1.50000000e+01 2.50000000e+01]]\n",
      "[[b'20230920 12:45:27' b'DWD' b'0']\n",
      " [b'20230920 12:45:27' b'Wetter.com' b'1']\n",
      " [b'20230920 12:45:27' b'Wetter.de' b'2']]\n",
      "[[2.02309180e+07 0.00000000e+00 1.65000000e+01 2.62999992e+01]\n",
      " [2.02309200e+07 1.00000000e+00 1.50000000e+01 2.40000000e+01]\n",
      " [2.02309200e+07 2.00000000e+00 1.50000000e+01 2.50000000e+01]]\n",
      "[[b'20230919 23:41:54' b'DWD' b'0']\n",
      " [b'20230919 23:41:54' b'Wetter.com' b'1']\n",
      " [b'20230919 23:41:54' b'Wetter.de' b'2']]\n"
     ]
    }
   ],
   "source": [
    "file1 = h5py.File('IU_scrape_data','r+')\n",
    "file2 = h5py.File('IU_scrape_data_BACKUP_1','r+')\n",
    "file1['data_float'].resize(3,axis=0)\n",
    "file1['data_string'].resize(3,axis=0)\n",
    "print(file1['data_float'][...])\n",
    "print(file1['data_string'][...])\n",
    "file1['data_float'][...] = file2['data_float'][...]\n",
    "file1['data_string'][...] = file2['data_string'][...]\n",
    "print(file1['data_float'][...])\n",
    "print(file1['data_string'][...])\n",
    "file1.close()\n",
    "file2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
